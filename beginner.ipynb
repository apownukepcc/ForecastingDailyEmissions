{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uj3iT-sPmzxa",
        "outputId": "b97848a2-31f6-49b9-9845-7a5e8eeb9a1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error on Test Data: 0.000089\n",
            "Prediction for the specified date: 2022-06-02\n",
            "Predicted Emissions/Load: 0.000023 tons/MW\n",
            "\n",
            "Actual Data from the Dataset:\n",
            "Actual Emissions/Load: 0.000025 tons/MW\n",
            "Parameters for the Day: {'tavg_emission': 26.8, 'tmin_emission': 20.0, 'tmax_emission': 33.9, 'prcp_emission': 3.0, 'snow_emission': 0.0, 'wdir_emission': 81, 'wspd_emission': 12.2, 'pres_emission': 1007.1, 'Source': 'LAKE-1', 'Parameter_emission': 'SO2TONS', 'Units_emission': 'TONS'}\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn import __version__ as sklearn_version\n",
        "from packaging import version\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"https://raw.githubusercontent.com/apownukepcc/ForecastingDailyEmissions/refs/heads/main/combinedWeatherValues.csv\"  # Replace with the actual path\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Convert 'date' column to datetime\n",
        "data['date'] = pd.to_datetime(data['date'])\n",
        "\n",
        "# Define emissions parameters and load\n",
        "emissions_params = ['SO2TONS', 'NOXTONS', 'COTONS']\n",
        "load_param = 'LOADMWBA'\n",
        "\n",
        "# Filter for Peak Season (May through August)\n",
        "peak_season = data[data['date'].dt.month.isin([5, 6, 7, 8])]\n",
        "\n",
        "# Separate emissions and load data\n",
        "emissions_data = peak_season[peak_season['Parameter'].isin(emissions_params)]\n",
        "load_data = peak_season[peak_season['Parameter'] == load_param]\n",
        "\n",
        "# Merge emissions and load data on date and source\n",
        "merged_data = pd.merge(\n",
        "    emissions_data,\n",
        "    load_data,\n",
        "    on=[\"date\", \"Source\"],\n",
        "    suffixes=(\"_emission\", \"_load\")\n",
        ")\n",
        "\n",
        "# Check if merged data is empty\n",
        "if merged_data.empty:\n",
        "    print(\"Merged data is empty. Check the filtering conditions or input data.\")\n",
        "    exit()\n",
        "\n",
        "# Calculate emissions/load\n",
        "merged_data[\"Emissions_Load\"] = merged_data[\"Value_emission\"] / merged_data[\"Value_load\"]\n",
        "\n",
        "# Define predictors and target\n",
        "predictors = ['tavg_emission', 'tmin_emission', 'tmax_emission', 'prcp_emission',\n",
        "              'snow_emission', 'wdir_emission', 'wspd_emission', 'pres_emission']\n",
        "categorical_features = ['Source', 'Parameter_emission', 'Units_emission']\n",
        "target = 'Emissions_Load'\n",
        "\n",
        "# Dynamic OneHotEncoder\n",
        "if version.parse(sklearn_version) >= version.parse(\"1.2\"):\n",
        "    one_hot_encoder = OneHotEncoder(drop=\"first\", sparse_output=False)  # For newer versions\n",
        "else:\n",
        "    one_hot_encoder = OneHotEncoder(drop=\"first\")  # For older versions (before 1.2)\n",
        "\n",
        "# Preprocess categorical and numeric features\n",
        "column_transformer = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', one_hot_encoder, categorical_features),\n",
        "        ('num', StandardScaler(), predictors)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Prepare features and target\n",
        "X = merged_data[predictors + categorical_features]\n",
        "y = merged_data[target]\n",
        "\n",
        "# Encode features\n",
        "X_encoded = column_transformer.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the Random Forest model\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f\"Mean Absolute Error on Test Data: {mae:.6f}\")\n",
        "\n",
        "# Function to predict and compare emissions/load for a specific date\n",
        "def predict_for_date(date_to_predict):\n",
        "    # Filter the merged dataset for the specified date\n",
        "    selected_day = merged_data[merged_data['date'] == pd.Timestamp(date_to_predict)]\n",
        "\n",
        "    if selected_day.empty:\n",
        "        print(f\"No data found for the specified date: {date_to_predict}\")\n",
        "        return\n",
        "\n",
        "    # Use the first matching row for prediction\n",
        "    selected_day = selected_day.iloc[0]\n",
        "\n",
        "    # Extract features for the selected day\n",
        "    selected_day_features = pd.DataFrame([{\n",
        "        **{col: selected_day[col] for col in predictors},\n",
        "        **{col: selected_day[col] for col in categorical_features}\n",
        "    }])\n",
        "\n",
        "    # Transform features for prediction\n",
        "    selected_day_encoded = column_transformer.transform(selected_day_features)\n",
        "    predicted_emissions_load = model.predict(selected_day_encoded)\n",
        "\n",
        "    # Output prediction and compare with actual value\n",
        "    print(f\"Prediction for the specified date: {date_to_predict}\")\n",
        "    print(f\"Predicted Emissions/Load: {predicted_emissions_load[0]:.6f} tons/MW\")\n",
        "    print(\"\\nActual Data from the Dataset:\")\n",
        "    print(f\"Actual Emissions/Load: {selected_day['Emissions_Load']:.6f} tons/MW\")\n",
        "    print(f\"Parameters for the Day: {selected_day[predictors + categorical_features].to_dict()}\")\n",
        "\n",
        "# Example usage for a specific date present in the dataset\n",
        "predict_for_date(\"2022-06-02\")\n"
      ]
    }
  ]
}